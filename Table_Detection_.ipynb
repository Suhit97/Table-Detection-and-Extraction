{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Table Detection .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfJLd3A0VmF+X9pH5zryiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suhit97/Table-Detection-and-Extraction/blob/main/Table_Detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voK3uA2_mgzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c8eb3b-4c02-423e-ecc4-def0a3304a11"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9He0uBGGduKm",
        "outputId": "4ff14b0f-998d-4dd1-9f4a-f168341faed1"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/table_detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/table_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpKDMsYt3IQV"
      },
      "source": [
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import random\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT5FMCAne_sG"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJhflMxfH34"
      },
      "source": [
        "import os\r\n",
        "import pathlib\r\n",
        "\r\n",
        "# Clone the tensorflow models repository if it doesn't already exist\r\n",
        "if \"models\" in pathlib.Path.cwd().parts:\r\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\r\n",
        "    os.chdir('..')\r\n",
        "elif not pathlib.Path('models').exists():\r\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sy5mq2Vfgfn"
      },
      "source": [
        "# Install the Object Detection API\r\n",
        "%%bash\r\n",
        "cd models/research/\r\n",
        "protoc object_detection/protos/*.proto --python_out=.\r\n",
        "cp object_detection/packages/tf2/setup.py .\r\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCYaQ1lrjYuY"
      },
      "source": [
        "#run model builder test\r\n",
        "!python models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5UwpV0-jDQS",
        "outputId": "a646f3a8-ae01-4db8-cc49-a54a19a76865"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import pandas as pd\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "\r\n",
        "\r\n",
        "def xml_to_csv(path):\r\n",
        "    xml_list = []\r\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\r\n",
        "        tree = ET.parse(xml_file)\r\n",
        "        root = tree.getroot()\r\n",
        "        for member in root.findall('object'):\r\n",
        "            value = (root.find('filename').text,\r\n",
        "                     int(root.find('size')[0].text),\r\n",
        "                     int(root.find('size')[1].text),\r\n",
        "                     member[0].text,\r\n",
        "                     int(member[4][0].text),\r\n",
        "                     int(member[4][1].text),\r\n",
        "                     int(member[4][2].text),\r\n",
        "                     int(member[4][3].text)\r\n",
        "                     )\r\n",
        "            xml_list.append(value)\r\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\r\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\r\n",
        "    return xml_df\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    for folder in ['train', 'test']:\r\n",
        "        image_path = os.path.join(os.getcwd(), ( folder + '/labels/'))\r\n",
        "        xml_df = xml_to_csv(image_path)\r\n",
        "        xml_df.to_csv((folder+'_labels.csv'), index=None)\r\n",
        "    print('Successfully converted xml to csv.')\r\n",
        "\r\n",
        "\r\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dto-zyb_mKxp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMh25bNXlE-W"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcEvyOGQm64L",
        "outputId": "d4239e50-efde-4b59-e224-5a397ee67b99"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=labels.csv --image_dir=train/images --output_path=train.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-17 18:46:23.224893: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-01-17 18:46:23.224950: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "Successfully created the TFRecords: /content/gdrive/My Drive/table_detection/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVuXnObInlz6"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=train_labels.csv --image_dir=train/images --output_path=train.record\r\n",
        "!python generate_tfrecord.py --csv_input=test_labels.csv --image_dir=test/images --output_path=test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlCnFQhrqfMZ"
      },
      "source": [
        "train_record_path = 'train.record'\r\n",
        "test_record_path = 'test.record'\r\n",
        "labelmap_path = 'labelmap.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHfSzOjArQQ4"
      },
      "source": [
        "## Configure Training\r\n",
        "Now that the data is ready it's time to create a training configuration. The OD API supports lots of models, each with its own config file. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19DSYpRVrNnY"
      },
      "source": [
        "batch_size = 5\r\n",
        "num_steps = 8000\r\n",
        "num_eval_steps = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCGsrbDbsJXN"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\r\n",
        "!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHnHb1ypsKA6"
      },
      "source": [
        "fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGZx0bOWvTv1"
      },
      "source": [
        "#!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\r\n",
        "\r\n",
        "base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RNfs4Cj2kwD",
        "outputId": "d3024ac6-4a42-48a3-8f54-3adea5a15b4f"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "print('Building model and restoring weights for fine-tuning...', flush=True)\r\n",
        "num_classes = 1\r\n",
        "pipeline_config = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'\r\n",
        "checkpoint_path = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'\r\n",
        "\r\n",
        "# Load pipeline config and build a detection model.\r\n",
        "#\r\n",
        "# Since we are working off of a COCO architecture which predicts 90\r\n",
        "# class slots by default, we override the `num_classes` field here to be just\r\n",
        "# one (for our new rubber ducky class).\r\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\r\n",
        "model_config = configs['model']\r\n",
        "model_config.ssd.num_classes = num_classes\r\n",
        "model_config.ssd.freeze_batchnorm = True\r\n",
        "detection_model = model_builder.build(\r\n",
        "      model_config=model_config, is_training=True)\r\n",
        "\r\n",
        "# Set up object-based checkpoint restore --- RetinaNet has two prediction\r\n",
        "# `heads` --- one for classification, the other for box regression.  We will\r\n",
        "# restore the box regression head but initialize the classification head\r\n",
        "# from scratch (we show the omission below by commenting out the line that\r\n",
        "# we would add if we wanted to restore both heads)\r\n",
        "fake_box_predictor = tf.compat.v2.train.Checkpoint(\r\n",
        "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\r\n",
        "    # _prediction_heads=detection_model._box_predictor._prediction_heads,\r\n",
        "    #    (i.e., the classification head that we *will not* restore)\r\n",
        "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\r\n",
        "    )\r\n",
        "fake_model = tf.compat.v2.train.Checkpoint(\r\n",
        "          _feature_extractor=detection_model._feature_extractor,\r\n",
        "          _box_predictor=fake_box_predictor)\r\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\r\n",
        "ckpt.restore(checkpoint_path).expect_partial()\r\n",
        "\r\n",
        "# Run model through a dummy image so that variables are created\r\n",
        "image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\r\n",
        "prediction_dict = detection_model.predict(image, shapes)\r\n",
        "_ = detection_model.postprocess(prediction_dict, shapes)\r\n",
        "print('Weights restored!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model and restoring weights for fine-tuning...\n",
            "Weights restored!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsYkX5Nozo9t"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "with open(base_config_path) as f:\r\n",
        "    config = f.read()\r\n",
        "\r\n",
        "with open('model_config.config', 'w') as f:\r\n",
        "  \r\n",
        "  # Set labelmap path\r\n",
        "  config = re.sub('label_map_path: \".*?\"', \r\n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\r\n",
        "  \r\n",
        "  # Set fine_tune_checkpoint path\r\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\r\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\r\n",
        "  \r\n",
        "  # Set train tf-record file path\r\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \r\n",
        "                 'input_path: \"{}\"'.format(train_record_path), config)\r\n",
        "  \r\n",
        "  # Set test tf-record file path\r\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \r\n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\r\n",
        "  \r\n",
        "  # Set number of classes.\r\n",
        "  config = re.sub('num_classes: [0-9]+',\r\n",
        "                  'num_classes: {}'.format(1), config)              # Enter the reqd no. of classes\r\n",
        "  \r\n",
        "  # Set batch size\r\n",
        "  config = re.sub('batch_size: [0-9]+',\r\n",
        "                  'batch_size: {}'.format(batch_size), config)\r\n",
        "  \r\n",
        "  # Set training steps\r\n",
        "  config = re.sub('num_steps: [0-9]+',\r\n",
        "                  'num_steps: {}'.format(num_steps), config)\r\n",
        "  \r\n",
        "  # Set fine-tune checkpoint type to detection\r\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \r\n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\r\n",
        "  \r\n",
        "  f.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER8C9z1bv_nU",
        "outputId": "9aa93c4d-eea2-45ab-d49d-858b642366a4"
      },
      "source": [
        "%cat model_config.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " # SSD with EfficientNet-b0 + BiFPN feature extractor,\n",
            "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n",
            "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n",
            "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n",
            "#\n",
            "# Train on TPU-8\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 1\n",
            "    add_background_class: false\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 3\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 512\n",
            "        max_dimension: 512\n",
            "        pad_to_max_dimension: true\n",
            "        }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 64\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          force_use_bias: true\n",
            "          activation: SWISH\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true\n",
            "            decay: 0.99\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 3\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_efficientnet-b0_bifpn_keras'\n",
            "      bifpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        num_iterations: 3\n",
            "        num_filters: 64\n",
            "      }\n",
            "      conv_hyperparams {\n",
            "        force_use_bias: true\n",
            "        activation: SWISH\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.99,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 1.5\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint: \"efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 5\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  use_bfloat16: true\n",
            "  num_steps: 8000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_scale_crop_and_pad_to_square {\n",
            "      output_size: 512\n",
            "      scale_min: 0.1\n",
            "      scale_max: 2.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 8e-2\n",
            "          total_steps: 300000\n",
            "          warmup_learning_rate: .001\n",
            "          warmup_steps: 2500\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"labelmap.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"train.record\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 5;\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"labelmap.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"test.record\"\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt7AQm8exfO1"
      },
      "source": [
        "## Train Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTKhDbfwJpg"
      },
      "source": [
        "model_dir = 'training/'\r\n",
        "pipeline_config_path = 'model_config.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlH9ffAkJIUe"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg12w3J773Tt"
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTQn_LepwViM"
      },
      "source": [
        "!python models/research/object_detection/model_main_tf2.py \\\r\n",
        "    --pipeline_config_path={pipeline_config_path} \\\r\n",
        "    --model_dir={model_dir} \\\r\n",
        "    --alsologtostderr \\\r\n",
        "    --num_train_steps={num_steps} \\\r\n",
        "    --sample_1_of_n_eval_examples=1 \\\r\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3toNkerUx0Eu"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir 'training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY_klCjsY-yx"
      },
      "source": [
        "## Export model Inference graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVSzEfk9ZDKt"
      },
      "source": [
        "The below code cell adds a line to the tf_utils.py file. This is a temporary fix to a [exporting issue](https://github.com/tensorflow/models/issues/8841) occuring when using the OD API with Tensorflow 2. This code will be removed as soon as the OD Team puts out a fix.\r\n",
        "\r\n",
        "All credit goes to Github user [Jacobsolawetz](https://github.com/Jacobsolawetz), who provided this [temporary fix](https://github.com/tensorflow/models/issues/8841#issuecomment-657647648)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDU2V5aJx-2n"
      },
      "source": [
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\r\n",
        "    tf_utils = f.read()\r\n",
        "\r\n",
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\r\n",
        "  # Set labelmap path\r\n",
        "  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\r\n",
        "  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\r\n",
        "  f.write(tf_utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoT9xbnnZRAq"
      },
      "source": [
        "output_directory = 'inference_graph'\r\n",
        "\r\n",
        "!python models/research/object_detection/exporter_main_v2.py \\\r\n",
        "    --trained_checkpoint_dir {model_dir} \\\r\n",
        "    --output_directory {output_directory} \\\r\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYBP-xyXZVS9"
      },
      "source": [
        "#from google.colab import files\r\n",
        "#files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn5AMYaKbNsl"
      },
      "source": [
        "## Test trained model on test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uc2aZxdbraT"
      },
      "source": [
        "import io\r\n",
        "import imageio\r\n",
        "import glob\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "from six import BytesIO\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "from IPython.display import display, Javascript\r\n",
        "from IPython.display import Image as IPyImage\r\n",
        "\r\n",
        "\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "from object_detection.utils import colab_utils\r\n",
        "from object_detection.builders import model_builder\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shh1MdC3aC8q"
      },
      "source": [
        "def load_image_into_numpy_array(path):\r\n",
        "  \"\"\"Load an image from file into a numpy array.\r\n",
        "\r\n",
        "  Puts image into numpy array to feed into tensorflow graph.\r\n",
        "  Note that by convention we put it into a numpy array with shape\r\n",
        "  (height, width, channels), where channels=3 for RGB.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    path: a file path (this can be local or on colossus)\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "  \"\"\"\r\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
        "  image = Image.open(BytesIO(img_data))\r\n",
        "  (im_width, im_height) = image.size\r\n",
        "  return np.array(image.getdata()).reshape(\r\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqjKqOLdbUPP"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLg6acVJbYBZ"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "model = tf.saved_model.load(f'{output_directory}/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8-753hHbzYI"
      },
      "source": [
        "def run_inference_for_single_image(model, image):\r\n",
        "  image = np.asarray(image)\r\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n",
        "  input_tensor = tf.convert_to_tensor(image)\r\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\r\n",
        "\r\n",
        "  # Run inference\r\n",
        "  model_fn = model.signatures['serving_default']\r\n",
        "  output_dict = model_fn(input_tensor)\r\n",
        "\r\n",
        "  # All outputs are batches tensors.\r\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n",
        "  # We're only interested in the first num_detections.\r\n",
        "  num_detections = int(output_dict.pop('num_detections'))\r\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \r\n",
        "                 for key,value in output_dict.items()}\r\n",
        "  output_dict['num_detections'] = num_detections\r\n",
        "\r\n",
        "  # detection_classes should be ints.\r\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n",
        "   \r\n",
        "  # Handle models with masks:\r\n",
        "  if 'detection_masks' in output_dict:\r\n",
        "    # Reframe the the bbox mask to the image size.\r\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n",
        "               image.shape[0], image.shape[1])      \r\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\r\n",
        "                                       tf.uint8)\r\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n",
        "    \r\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK1HRH3lcJc3"
      },
      "source": [
        "\r\n",
        "for image_path in glob.glob('test/images/*.jpg'):\r\n",
        "  image_np = load_image_into_numpy_array(image_path)\r\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\r\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np,\r\n",
        "      output_dict['detection_boxes'],\r\n",
        "      output_dict['detection_classes'],\r\n",
        "      output_dict['detection_scores'],\r\n",
        "      category_index,\r\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      line_thickness=8)\r\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKSLv3-PcTcM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}